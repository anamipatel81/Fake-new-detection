# Fake News Detection Model

## Overview
The Fake News Detection Model is a machine learning-based web application designed to classify news articles as "Fake" or "Real" based on their title and content. It leverages natural language processing (NLP) techniques and supervised learning algorithms to analyze text data and make predictions. The application is built using Python, Flask, and machine learning libraries and can be deployed locally or on the cloud.

---

## Features
- **Preprocessing**: Cleans text by removing special characters, stopwords, and lemmatizing using WordNet Lemmatizer.
- **Feature Engineering**:
  - Text length and word density.
  - Sentiment analysis using VADER.
  - Readability scores (Flesch-Kincaid grade).
- **Machine Learning Pipeline**:
  - Text vectorization using TF-IDF.
  - Dimensionality reduction using Truncated SVD.
  - Classification using a pre-trained model (e.g., Random Forest, Logistic Regression, or XGBoost).
- **Web Application**: Interactive web interface built with Flask for users to input news articles and view predictions.
- **Deployment**: Easily shareable via ngrok or deployable on platforms like Heroku or Render.

---

## Installation

### Prerequisites
Ensure you have the following installed:
- Python 3.8 or higher
- pip (Python package manager)

### Clone the Repository
```bash
git clone https://github.com/your-repository/fake-news-detection.git
cd fake-news-detection
```

### Install Dependencies
```bash
pip install -r requirements.txt
```

### Download Required NLTK Data
Run the following commands in Python to download NLTK resources:
```python
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('vader_lexicon')
```

---

## Usage

### Run Locally
1. Start the Flask app:
   ```bash
   python app.py
   ```
2. Open your browser and navigate to:
   ```
   http://127.0.0.1:5000/
   ```
3. Input a news title and content to check if it is "Fake" or "Real".

### Share Publicly with ngrok
1. Install ngrok:
   ```bash
   pip install pyngrok
   ```
2. Authenticate ngrok with your token:
   ```python
   from pyngrok import ngrok
   ngrok.set_auth_token("<your-authtoken>")
   ```
3. Run ngrok alongside the Flask app:
   ```python
   from pyngrok import ngrok
   public_url = ngrok.connect(5000)
   print("ngrok Public URL:", public_url)
   ```
4. Share the public URL generated by ngrok.

---

## File Structure
```
.
├── app.py                  # Main Flask application
├── requirements.txt        # Python dependencies
├── templates/              # HTML templates
│   └── index.html          # Main web page
├── tfidf_title.pkl         # Saved TF-IDF vectorizer for titles
├── tfidf_text.pkl          # Saved TF-IDF vectorizer for text
├── svd.pkl                 # Saved Truncated SVD object
├── model.pkl               # Saved trained machine learning model
└── README.md               # Project documentation
```

---

## How It Works

### Preprocessing
1. Cleans input text by:
   - Removing special characters.
   - Converting text to lowercase.
   - Removing stopwords using NLTK.
   - Lemmatizing words with WordNet Lemmatizer.

### Feature Engineering
- Calculates features such as text length, word density, readability scores, and sentiment analysis.

### Machine Learning Pipeline
1. **TF-IDF Vectorization**:
   - Extracts numerical features from text.
2. **Dimensionality Reduction**:
   - Reduces high-dimensional TF-IDF vectors using Truncated SVD.
3. **Classification**:
   - Uses a trained machine learning model to predict whether the news is "Fake" or "Real."

---

## Technologies Used
- **Python**: Core programming language.
- **Flask**: Web framework for the application.
- **Scikit-learn**: Machine learning library.
- **NLTK**: Natural Language Toolkit for text preprocessing.
- **pyngrok**: For sharing the app locally.
- **textstat**: For calculating readability scores.

